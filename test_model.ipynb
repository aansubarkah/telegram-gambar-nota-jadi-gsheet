{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "be454",
    "vscode": {
     "languageId": "swift"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://nano-gpt.com/api/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer sk-nano-76e82f54-5899-4eeb-9134-afc7d1a1e577\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"model\": \"gpt-5.1\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellUniqueIdByVincent": "7eeaa"
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellUniqueIdByVincent": "fb94a"
   },
   "outputs": [],
   "source": [
    "NANOGPT_API_KEY: str = 'sk-nano-74903cd0-0093-461c-a0ef-e28afd0a05a8'\n",
    "NANOGPT_API_URL: str = \"https://nano-gpt.com/api/v1/chat/completions\"\n",
    "    \n",
    "# Vision model for invoice extraction (gpt-4o has vision capability)\n",
    "AI_MODEL: str = \"Qwen/Qwen3-VL-235B-A22B-Instruct\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellUniqueIdByVincent": "6077c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-1767150568094ohkyx', 'object': 'chat.completion', 'created': 1767150568, 'model': 'Qwen/Qwen3-VL-235B-A22B-Instruct', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Hello! üòä  \\nI‚Äôm doing great‚Äîthank you for asking! I‚Äôm Qwen, a large-scale language model independently developed by Alibaba Group. I‚Äôm not based on any other existing models like GPT or LLaMA‚ÄîI‚Äôm a native Alibaba model, trained entirely on our own data and infrastructure.\\n\\nI come in different versions (like Qwen, Qwen2, Qwen3, etc.), and I can handle tasks such as answering questions, writing stories, coding, logical reasoning, and even playing games or chatting casually. I also support multiple languages and have strong capabilities in both Chinese and English.\\n\\nLet me know how I can help you‚ÄîI‚Äôm here to assist with anything you need! üåü\\n\\nP.S. If you‚Äôre curious about my latest version or technical specs, feel free to ask‚ÄîI‚Äôll be happy to share more!'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 174, 'total_tokens': 194}, 'cost': 0, 'paymentSource': None}\n"
     ]
    }
   ],
   "source": [
    "url = NANOGPT_API_URL \n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer \" + NANOGPT_API_KEY,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"model\": AI_MODEL,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Hello, how are you? which model are you using?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "829aa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellUniqueIdByVincent": "92836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "\n",
      "Vision-capable models found: 6\n",
      "  - qwen3-vl-235b-a22b-thinking\n",
      "  - qwen3-vl-235b-a22b-instruct-original\n",
      "  - meta-llama/llama-3.2-90b-vision-instruct\n",
      "  - qwen25-vl-72b-instruct\n",
      "  - OpenGVLab/InternVL3-78B\n",
      "  - Qwen/Qwen3-VL-235B-A22B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# Get available models from NanoGPT\n",
    "models_url = \"https://nano-gpt.com/api/v1/models\"\n",
    "models_response = requests.get(models_url, headers={\"Authorization\": \"Bearer \" + NANOGPT_API_KEY})\n",
    "print(f\"Status: {models_response.status_code}\")\n",
    "models_data = models_response.json()\n",
    "\n",
    "# Filter for vision-capable models\n",
    "vision_models = [m for m in models_data.get('data', []) if 'vision' in m.get('id', '').lower() or 'vl' in m.get('id', '').lower() or '4o' in m.get('id', '').lower()]\n",
    "print(f\"\\nVision-capable models found: {len(vision_models)}\")\n",
    "for m in vision_models[:20]:\n",
    "    print(f\"  - {m.get('id')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellUniqueIdByVincent": "61835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing model: chatgpt-4o-latest\n",
      "  ‚ùå Error 402: {\"error\":{\"message\":\"Insufficient balance. Multiple payment options available. Payment required: $0.\n",
      "\n",
      "Testing model: gpt-4o\n",
      "  ‚ùå Error 402: {\"error\":{\"message\":\"Insufficient balance. Multiple payment options available. Payment required: $0.\n",
      "\n",
      "Testing model: Qwen/Qwen3-VL-235B-A22B-Instruct\n",
      "  ‚úÖ SUCCESS: Solid green screen....\n",
      "\n",
      "Testing model: qwen25-vl-72b-instruct\n",
      "  ‚úÖ SUCCESS: The image is plain light green with no visible content or details....\n"
     ]
    }
   ],
   "source": [
    "# Test vision models with an actual image\n",
    "import base64\n",
    "\n",
    "# Create a simple test image (1x1 pixel PNG)\n",
    "test_image_base64 = \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==\"\n",
    "\n",
    "test_models = [\n",
    "    \"chatgpt-4o-latest\",  # From the docs example\n",
    "    \"gpt-4o\",\n",
    "    \"Qwen/Qwen3-VL-235B-A22B-Instruct\",\n",
    "    \"qwen25-vl-72b-instruct\",\n",
    "]\n",
    "\n",
    "for model in test_models:\n",
    "    print(f\"\\nTesting model: {model}\")\n",
    "    try:\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"What is in this image? Reply briefly.\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{test_image_base64}\"}}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 100\n",
    "        }\n",
    "        \n",
    "        resp = requests.post(NANOGPT_API_URL, headers=headers, json=payload, timeout=60)\n",
    "        if resp.status_code == 200:\n",
    "            content = resp.json()['choices'][0]['message']['content']\n",
    "            print(f\"  ‚úÖ SUCCESS: {content[:80]}...\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Error {resp.status_code}: {resp.text[:100]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Exception: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basangdata12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vincent": {
   "sessionId": "083ced2fdec6e8d07eb0cc17_2025-12-31T03-00-56-648Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
